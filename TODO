read syntax.rs TODOs (line 83 and others)

lexer isnt really a lexer, more like a categorizer/classifier/parser

tokenizer -> indicate (row, col) error
> see reader.rs for the implementation of a custom Iterator to do just that

use Result to wrap return types where needed (tokenizer, lexer, parser, ...)

save the tokenizer classification and maybe reuse it later in the lexer
> the same thing could be done with the lexer

write cpu class and tests for that
> read and write a register

write simple field evaluator

write memory class and tests for that

//(DONE) maybe i could separate the Lexer trait into two: one very simple,
//which has the signature/definition of str_to_token and parse; another one
//which has the signatures/definitions of 'is_*' and 'str_to_*' and which
//actually uses a predefined enum also declared here which has the variants
//'Number, String, Symbol, ...'. The implementation of this lexer would then
//have the job to map the words from the tokenizer into that Enum.
